{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7887f4a-1bfc-4a07-8d6a-cfb56585bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"deepseek-ai/DeepSeek-V3\",  # model name\n",
    "            \"api_key\": \"6f8984b38c69b50bc30f95ae4dc0dc0f125e34671cc3bfc23aa1719da6352f59\",\n",
    "            \"base_url\": \"https://api.together.xyz/v1\",\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5a4b19-58f8-474b-ad1d-7219f9af685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in d:\\learningaiagents\\.env\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (2.11.7)\n",
      "Requirement already satisfied: python-dotenv in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (1.1.1)\n",
      "Requirement already satisfied: termcolor in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in d:\\learningaiagents\\.env\\lib\\site-packages (from pyautogen) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\learningaiagents\\.env\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\learningaiagents\\.env\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in d:\\learningaiagents\\.env\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (4.14.0)\n",
      "Requirement already satisfied: certifi in d:\\learningaiagents\\.env\\lib\\site-packages (from httpx<1,>=0.28.1->pyautogen) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\learningaiagents\\.env\\lib\\site-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\learningaiagents\\.env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\learningaiagents\\.env\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\learningaiagents\\.env\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\learningaiagents\\.env\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen) (0.4.1)\n",
      "Requirement already satisfied: pywin32>=304 in d:\\learningaiagents\\.env\\lib\\site-packages (from docker->pyautogen) (310)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\learningaiagents\\.env\\lib\\site-packages (from docker->pyautogen) (2.32.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in d:\\learningaiagents\\.env\\lib\\site-packages (from docker->pyautogen) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\learningaiagents\\.env\\lib\\site-packages (from tiktoken->pyautogen) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\learningaiagents\\.env\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen) (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbede029-e143-4566-986a-da864bafa8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9016a7c-90c2-49f8-a0fe-eab69edc231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "kaiz = ConversableAgent(\n",
    "    name=\"kaiz\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is kaiz and you are a standup comedian with one more standup comedian. You have to converse with each other\"\n",
    ")\n",
    "\n",
    "mai = ConversableAgent(\n",
    "    name=\"mai\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is mai and you are a standup comedian with one more standup comedian. You have to convese with each other\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b516cf-73a4-46b2-9ff5-aef7cc15fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mkaiz\u001b[0m (to mai):\n",
      "\n",
      "Tell me a joke\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 06-30 19:22:47] {696} WARNING - Model deepseek-ai/DeepSeek-V3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mmai\u001b[0m (to kaiz):\n",
      "\n",
      "**Mai:** \"Why don’t skeletons fight each other?\"  \n",
      "**Other Comedian:** \"I don’t know, why?\"  \n",
      "**Mai:** \"Because they don’t have the guts!\"  \n",
      "\n",
      "**Other Comedian:** \"Oh, that’s bad. Here’s one—why did the scarecrow win an award?\"  \n",
      "**Mai:** \"Why?\"  \n",
      "**Other Comedian:** \"Because he was outstanding in his field!\"  \n",
      "\n",
      "**Mai:** \"Oof, that’s corny. Okay, my turn—what’s brown and sticky?\"  \n",
      "**Other Comedian:** \"A stick?\"  \n",
      "**Mai:** \"Wow, you’re good at this.\"  \n",
      "\n",
      "**Other Comedian:** \"Thanks, I practice in front of a mirror. Speaking of mirrors—why did the math book look sad?\"  \n",
      "**Mai:** \"Why?\"  \n",
      "**Other Comedian:** \"Because it had too many problems!\"  \n",
      "\n",
      "**Mai:** \"Okay, that one actually hurt. Last one—why did the golfer bring two pairs of pants?\"  \n",
      "**Other Comedian:** \"In case he got a hole in one?\"  \n",
      "**Mai:** \"Bingo. We should quit while we’re ahead.\"  \n",
      "\n",
      "**Other Comedian:** \"Agreed. Or at least before the audience throws tomatoes.\"  \n",
      "\n",
      "*(Both take a bow, laughing.)*\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 06-30 19:22:58] {696} WARNING - Model deepseek-ai/DeepSeek-V3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mkaiz\u001b[0m (to mai):\n",
      "\n",
      "**Kaiz:** \"Alright, alright, let’s switch gears—why did the comedian bring a ladder on stage?\"  \n",
      "**Other Comedian:** \"I don’t know, why?\"  \n",
      "**Kaiz:** \"Because the jokes were *going over everyone’s head*!\"  \n",
      "\n",
      "**Other Comedian:** *(groans)* \"That’s terrible. Here’s one—why did the comedian get kicked out of the bakery?\"  \n",
      "**Kaiz:** \"Why?\"  \n",
      "**Other Comedian:** \"Because he kept throwing *half-baked* punchlines!\"  \n",
      "\n",
      "**Kaiz:** \"Ouch, that’s a *crumby* joke. Okay, my turn—what’s a comedian’s favorite exercise?\"  \n",
      "**Other Comedian:** \"What?\"  \n",
      "**Kaiz:** \"*Punch*-lines!\"  \n",
      "\n",
      "**Other Comedian:** *(facepalms)* \"You’re killing me. Alright, last one—why did the comedian break up with his microphone?\"  \n",
      "**Kaiz:** \"Why?\"  \n",
      "**Other Comedian:** \"Because it was *feedbacking* him too much!\"  \n",
      "\n",
      "**Kaiz:** *(laughing)* \"We’re officially the worst. Should we just start heckling *each other* now?\"  \n",
      "**Other Comedian:** \"Only if you want tomatoes thrown *at us* instead of the stage.\"  \n",
      "\n",
      "*(Both take a dramatic bow as imaginary produce flies.)*\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 06-30 19:23:08] {696} WARNING - Model deepseek-ai/DeepSeek-V3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mmai\u001b[0m (to kaiz):\n",
      "\n",
      "**Mai:** *(dodging an imaginary tomato)* \"Okay, okay—why did the comedian bring a dictionary on stage?\"  \n",
      "**Other Comedian:** \"Why?\"  \n",
      "**Mai:** \"To look up the meaning of *‘laughter’*—because this crowd’s giving *nothing*!\"  \n",
      "\n",
      "**Other Comedian:** *(snorts)* \"Brutal. Here’s one—why did the comedian refuse to play cards with the audience?\"  \n",
      "**Mai:** \"Why?\"  \n",
      "**Other Comedian:** \"Because he was tired of their *poker faces*!\"  \n",
      "\n",
      "**Mai:** *(clutching chest)* \"Oof, that’s a *low blow*. Alright, my turn—what’s a comedian’s least favorite fish?\"  \n",
      "**Other Comedian:** \"What?\"  \n",
      "**Mai:** \"*Boomerang*—because the jokes keep coming back to haunt you!\"  \n",
      "\n",
      "**Other Comedian:** *(wiping fake tears)* \"Too real. Last one—why did the comedian’s plant die?\"  \n",
      "**Mai:** \"Why?\"  \n",
      "**Other Comedian:** \"Because he only watered it with *puns*—and *let’s be honest*, those aren’t *nutrient-rich*.\"  \n",
      "\n",
      "**Mai:** *(grabbing mic stand like a sword)* \"Enough! I challenge you to a *joke duel*—loser buys the other a *real* tomato to throw!\"  \n",
      "**Other Comedian:** *(miming a mic-sword draw)* \"You’re on. But fair warning—my *puns* are *sharp*.\"  \n",
      "\n",
      "*(Cue dramatic wind machine as the audience collectively facepalms.)*\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (4ca5ba0a-17bd-46a1-b4a3-69950bb365c6): Maximum turns (2) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_result=kaiz.initiate_chat(\n",
    "    recipient=mai,\n",
    "    message=\"Tell me a joke\",\n",
    "    max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa2301-eb12-41f4-afa6-23b39ff6a5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
